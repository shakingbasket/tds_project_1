{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rsY8MTDTFgEm"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# GitHub Personal Access Token (optional if you face rate limits)\n",
        "GITHUB_TOKEN = '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'\n",
        "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
        "\n",
        "\n",
        "# Helper function to clean company names\n",
        "def clean_company_name(company):\n",
        "    if company:\n",
        "        company = company.strip().lstrip('@').upper()\n",
        "    return company\n",
        "\n",
        "# Fetch users in Delhi with more than 100 followers\n",
        "def get_github_users(location='Delhi', min_followers=100):\n",
        "    url = f\"https://api.github.com/search/users?q=location:{location}+followers:>{min_followers}&per_page=100\"\n",
        "    users = []\n",
        "    while url:\n",
        "        response = requests.get(url, headers=HEADERS).json()\n",
        "        users.extend(response.get('items', []))\n",
        "        if 'next' in response:\n",
        "            url = response['next']\n",
        "        else:\n",
        "            url = None\n",
        "        time.sleep(2)\n",
        "    return users\n",
        "\n",
        "# Fetch detailed user info\n",
        "def get_user_details(username):\n",
        "    url = f\"https://api.github.com/users/{username}\"\n",
        "    return requests.get(url, headers=HEADERS).json()\n",
        "\n",
        "# Fetch repositories for each user\n",
        "def get_user_repositories(username):\n",
        "    repos = []\n",
        "    url = f\"https://api.github.com/users/{username}/repos?per_page=100\"\n",
        "\n",
        "    while url:\n",
        "        response = requests.get(url, headers=HEADERS)\n",
        "        response_data = response.json()\n",
        "        repos.extend(response_data)\n",
        "\n",
        "        # Check for pagination in headers\n",
        "        if 'Link' in response.headers:\n",
        "            links = response.headers['Link']\n",
        "            next_link = [link for link in links.split(',') if 'rel=\"next\"' in link]\n",
        "            if next_link:\n",
        "                url = next_link[0].split(';')[0].strip()[1:-1]  # Extract the URL\n",
        "            else:\n",
        "                url = None  # No more pages\n",
        "        else:\n",
        "            url = None  # No pagination header\n",
        "\n",
        "        time.sleep(2)  # To respect the rate limits\n",
        "\n",
        "    return repos\n",
        "\n",
        "# Fetch users\n",
        "users = get_github_users()\n",
        "\n",
        "# Initialize lists to hold user and repository data\n",
        "user_data = []\n",
        "repo_data = []\n",
        "\n",
        "# Fetch details and repos for each user\n",
        "for user in users:\n",
        "    user_details = get_user_details(user['login'])\n",
        "\n",
        "    user_info = {\n",
        "        'login': user_details.get('login'),\n",
        "        'name': user_details.get('name'),\n",
        "        'company': clean_company_name(user_details.get('company')),\n",
        "        'location': user_details.get('location'),\n",
        "        'email': user_details.get('email'),\n",
        "        'hireable': user_details.get('hireable', False),\n",
        "        'bio': user_details.get('bio'),\n",
        "        'public_repos': user_details.get('public_repos'),\n",
        "        'followers': user_details.get('followers'),\n",
        "        'following': user_details.get('following'),\n",
        "        'created_at': user_details.get('created_at')\n",
        "    }\n",
        "\n",
        "    user_data.append(user_info)\n",
        "\n",
        "    # Fetch user repositories\n",
        "    repos = get_user_repositories(user['login'])\n",
        "    for repo in repos[:500]:  # Limit to 500 repos per user\n",
        "        repo_info = {\n",
        "            'login': user['login'],\n",
        "            'full_name': repo.get('full_name'),\n",
        "            'created_at': repo.get('created_at'),\n",
        "            'stargazers_count': repo.get('stargazers_count', 0),\n",
        "            'watchers_count': repo.get('watchers_count', 0),\n",
        "            'language': repo.get('language'),\n",
        "            'has_projects': repo.get('has_projects', False),\n",
        "            'has_wiki': repo.get('has_wiki', False),\n",
        "            'license_name': repo.get('license')['key'] if repo.get('license') else None\n",
        "        }\n",
        "        repo_data.append(repo_info)\n",
        "\n",
        "# Convert to DataFrames\n",
        "df_users = pd.DataFrame(user_data)\n",
        "df_repos = pd.DataFrame(repo_data)\n",
        "\n",
        "# Save to CSV files\n",
        "df_users.to_csv('users.csv', index=False)\n",
        "df_repos.to_csv('repositories.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Perform Data Analysis"
      ],
      "metadata": {
        "id": "B3vPyoILH8Mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import linregress\n",
        "\n",
        "\n",
        "# Load the data from CSV files\n",
        "df_users = pd.read_csv('users.csv')\n",
        "df_repos = pd.read_csv('repositories.csv')\n",
        "\n",
        "df_users['created_at'] = pd.to_datetime(df_users['created_at'], errors='coerce')\n",
        "\n",
        "# 1. Top 5 users by followers\n",
        "top_5_followers = df_users.nlargest(5, 'followers')['login'].tolist()\n",
        "print(f\"Top 5 users by followers: {', '.join(top_5_followers)}\")\n",
        "\n",
        "# 2. Top 5 earliest registered users\n",
        "earliest_users = df_users.nsmallest(5, 'created_at')['login'].tolist()\n",
        "print(f\"Top 5 earliest users: {', '.join(earliest_users)}\")\n",
        "\n",
        "# 3. Top 3 most popular licenses\n",
        "popular_licenses = df_repos['license_name'].dropna().value_counts().head(3).index.tolist()\n",
        "print(f\"Top 3 licenses: {', '.join(popular_licenses)}\")\n",
        "\n",
        "# 4. Most common company\n",
        "most_common_company = df_users['company'].mode()[0]\n",
        "print(f\"Most common company: {most_common_company}\")\n",
        "\n",
        "# 5. Most popular language\n",
        "most_popular_language = df_repos['language'].mode()[0]\n",
        "print(f\"Most popular language: {most_popular_language}\")\n",
        "\n",
        "# 6. Second most popular language for users who joined after 2020\n",
        "df_recent_users = df_users[pd.to_datetime(df_users['created_at']).dt.year > 2020]\n",
        "second_popular_language = df_repos[df_repos['login'].isin(df_recent_users['login'])]['language'].value_counts().index[1]\n",
        "print(f\"Second most popular language (after 2020): {second_popular_language}\")\n",
        "\n",
        "# 7. Language with the highest average stars per repository\n",
        "avg_stars_per_language = df_repos.groupby('language')['stargazers_count'].mean().idxmax()\n",
        "print(f\"Language with highest average stars per repo: {avg_stars_per_language}\")\n",
        "\n",
        "# 8. Top 5 by leader_strength (followers / (1 + following))\n",
        "df_users['leader_strength'] = df_users['followers'] / (1 + df_users['following'])\n",
        "top_5_leader_strength = df_users.nlargest(5, 'leader_strength')['login'].tolist()\n",
        "print(f\"Top 5 by leader_strength: {', '.join(top_5_leader_strength)}\")\n",
        "\n",
        "# 9. Correlation between followers and public repos\n",
        "correlation_followers_repos = df_users[['followers', 'public_repos']].corr().loc['followers', 'public_repos']\n",
        "print(f\"Correlation between followers and public repos: {correlation_followers_repos:.3f}\")\n",
        "\n",
        "# 10. Regression slope of followers on public repos\n",
        "slope, intercept, r_value, p_value, std_err = linregress(df_users['public_repos'], df_users['followers'])\n",
        "print(f\"Regression slope of followers on repos: {slope:.3f}\")\n",
        "\n",
        "# 11. Correlation between projects enabled and wiki enabled\n",
        "correlation_projects_wiki = df_repos[['has_projects', 'has_wiki']].corr().loc['has_projects', 'has_wiki']\n",
        "print(f\"Correlation between projects and wiki enabled: {correlation_projects_wiki:.3f}\")\n",
        "\n",
        "# 12. Do hireable users follow more people than those who are not hireable?\n",
        "hireable_users_following = df_users[df_users['hireable'] == True]['following'].mean()\n",
        "non_hireable_users_following = df_users[df_users['hireable'] == False]['following'].mean()\n",
        "difference_in_following = hireable_users_following - non_hireable_users_following\n",
        "print(f\"Average following for hireable minus non-hireable users: {difference_in_following:.3f}\")\n",
        "\n",
        "# 13. Correlation between bio length and followers\n",
        "df_users['bio_length'] = df_users['bio'].apply(lambda x: len(x) if isinstance(x, str) else 0)  # Length of bio in Unicode characters\n",
        "slope_bio_followers, intercept, r_value, p_value, std_err = linregress(df_users['bio_length'], df_users['followers'])\n",
        "print(f\"Regression slope of followers on bio length: {slope_bio_followers:.3f}\")\n",
        "\n",
        "# 14. Who created the most repositories on weekends (UTC)?\n",
        "df_repos['created_at'] = pd.to_datetime(df_repos['created_at'])\n",
        "df_repos['is_weekend'] = df_repos['created_at'].dt.dayofweek >= 5  # 5 and 6 correspond to Saturday and Sunday\n",
        "weekend_repo_counts = df_repos[df_repos['is_weekend']].groupby('login')['full_name'].count().nlargest(5).index.tolist()\n",
        "print(f\"Top 5 users who created the most repositories on weekends: {', '.join(weekend_repo_counts)}\")\n",
        "\n",
        "# 15. Do hireable users share their email addresses more often?\n",
        "hireable_with_email = df_users[df_users['hireable'] == True]['email'].notna().mean()\n",
        "non_hireable_with_email = df_users[df_users['hireable'] == False]['email'].notna().mean()\n",
        "difference_in_email_sharing = hireable_with_email - non_hireable_with_email\n",
        "print(f\"Fraction of hireable users with email minus non-hireable: {difference_in_email_sharing:.3f}\")\n",
        "\n",
        "# 16. Most common surname\n",
        "df_users['surname'] = df_users['name'].apply(lambda x: x.split()[-1].upper() if isinstance(x, str) and len(x.split()) > 1 else None)\n",
        "most_common_surname = df_users['surname'].dropna().value_counts().nlargest(1).index.tolist()\n",
        "print(f\"Most common surname: {', '.join(most_common_surname)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0L16_TVH5xh",
        "outputId": "804fe3bc-6200-47a4-d964-1e6e721ff064"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users by followers: amitshekhariitbhu, shradha-khapra, loveBabbar, Nakshatra05, Anuj-Kumar-Sharma\n",
            "Top 5 earliest users: dufferzafar, nathvarun, aviaryan, softvar, rishikksh20\n",
            "Top 3 licenses: mit, apache-2.0, gpl-3.0\n",
            "Most common company: CODING BLOCKS\n",
            "Most popular language: JavaScript\n",
            "Second most popular language (after 2020): HTML\n",
            "Language with highest average stars per repo: Java\n",
            "Top 5 by leader_strength: Anuj-Kumar-Sharma, Ignitetechnologies, shradha-khapra, loveBabbar, amitshekhariitbhu\n",
            "Correlation between followers and public repos: -0.134\n",
            "Regression slope of followers on repos: -2.379\n",
            "Correlation between projects and wiki enabled: 0.228\n",
            "Average following for hireable minus non-hireable users: nan\n",
            "Regression slope of followers on bio length: 9.109\n",
            "Top 5 users who created the most repositories on weekends: Ayush7614, shivaylamba, amitsrivastava4all, manrajgrover, AkshayAnand2002\n",
            "Fraction of hireable users with email minus non-hireable: nan\n",
            "Most common surname: SINGH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Values\n",
        "\n",
        "During the data analysis process, we encountered several missing values in our dataset. To ensure the integrity and accuracy of our results, we made the following assumptions and handled the missing values as outlined below:\n",
        "\n",
        "1. **Hireable Status:**\n",
        "   - For users with a missing `hireable` status, we assumed they are **not hireable**. Therefore, we filled these missing values with `False`.\n",
        "\n",
        "2. **Following Count:**\n",
        "   - Users without a recorded number of followers were assumed to have **no following**. We replaced any missing values in the `following` column with `0`.\n",
        "\n",
        "3. **Email Availability:**\n",
        "   - Users who did not provide an email address were considered as not sharing their email. We filled missing values in the `email` column with an empty string (`''`), allowing us to determine whether a user shared their email or not based on whether the string is empty.\n",
        "\n",
        "4. **Overall Data Integrity:**\n",
        "   - By adopting these assumptions, we aimed to create a more consistent dataset for analysis. While some assumptions may not reflect the true circumstances for every user, they allow for a more straightforward and systematic analysis, enabling us to derive meaningful insights.\n",
        "\n",
        "These assumptions were critical in enabling our analysis and ensuring that missing data did not skew our results.\n"
      ],
      "metadata": {
        "id": "sFStgskbSm48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values more carefully and without inplace=True\n",
        "df_users['hireable'] = df_users['hireable'].fillna(False)\n",
        "df_users['following'] = df_users['following'].fillna(0)\n",
        "df_users['email'] = df_users['email'].fillna('')\n",
        "\n",
        "# Correct calculations\n",
        "\n",
        "# 12. Do hireable users follow more people than those who are not hireable?\n",
        "hireable_users_following = df_users[df_users['hireable'] == True]['following'].mean()\n",
        "non_hireable_users_following = df_users[df_users['hireable'] == False]['following'].mean()\n",
        "difference_in_following = hireable_users_following - non_hireable_users_following\n",
        "print(f\"Average following for hireable minus non-hireable users: {difference_in_following:.3f}\")\n",
        "\n",
        "# 15. Do hireable users share their email addresses more often?\n",
        "hireable_with_email = df_users[df_users['hireable'] == True]['email'].apply(lambda x: bool(x)).mean()\n",
        "non_hireable_with_email = df_users[df_users['hireable'] == False]['email'].apply(lambda x: bool(x)).mean()\n",
        "difference_in_email_sharing = hireable_with_email - non_hireable_with_email\n",
        "print(f\"Fraction of hireable users with email minus non-hireable: {difference_in_email_sharing:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8kFu8yqMPWg",
        "outputId": "b7c3ab72-a869-47ca-9796-1462569cbb87"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average following for hireable minus non-hireable users: -695.468\n",
            "Fraction of hireable users with email minus non-hireable: 0.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9jzUDnxzSxxk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}